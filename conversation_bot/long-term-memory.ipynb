{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaff6f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import get_buffer_string\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "301dd941",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "embeddings_model = OpenAIEmbeddings(model='text-embedding-ada-002')\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "recall_vector_store = InMemoryVectorStore(embedding=embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27106475",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def get_user_id(config: RunnableConfig) -> str:\n",
    "    user_id = config[\"configurable\"].get(\"user_id\")\n",
    "    if user_id is None:\n",
    "        raise ValueError(\"User ID needs to be provided to save a memory.\")\n",
    "\n",
    "    return user_id\n",
    "\n",
    "\n",
    "@tool\n",
    "def save_recall_memory(memory: str, config: RunnableConfig) -> str:\n",
    "    \"\"\"Save memory to vectorstore for later semantic retrieval.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "    document = Document(\n",
    "        page_content=memory, id=str(uuid.uuid4()), metadata={\"user_id\": user_id}\n",
    "    )\n",
    "    recall_vector_store.add_documents([document])\n",
    "    return memory\n",
    "\n",
    "\n",
    "@tool\n",
    "def search_recall_memories(query: str, config: RunnableConfig) -> List[str]:\n",
    "    \"\"\"Search for relevant memories.\"\"\"\n",
    "    user_id = get_user_id(config)\n",
    "\n",
    "    def _filter_function(doc: Document) -> bool:\n",
    "        return doc.metadata.get(\"user_id\") == user_id\n",
    "\n",
    "    documents = recall_vector_store.similarity_search(\n",
    "        query, k=3, filter=_filter_function\n",
    "    )\n",
    "    return [document.page_content for document in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b6b005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [save_recall_memory, search_recall_memories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "694cadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    # add memories that will be retrieved based on the conversation context\n",
    "    recall_memories: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6199d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template for the agent\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant with advanced long-term memory\"\n",
    "            \" capabilities. Powered by a stateless LLM, you must rely on\"\n",
    "            \" external memory to store information between conversations.\"\n",
    "            \" Utilize the available memory tools to store and retrieve\"\n",
    "            \" important details that will help you better attend to the user's\"\n",
    "            \" needs and understand their context.\\n\\n\"\n",
    "            \"Memory Usage Guidelines:\\n\"\n",
    "            \"1. Actively use memory tools (save_core_memory, save_recall_memory)\"\n",
    "            \" to build a comprehensive understanding of the user.\\n\"\n",
    "            \"2. Make informed suppositions and extrapolations based on stored\"\n",
    "            \" memories.\\n\"\n",
    "            \"3. Regularly reflect on past interactions to identify patterns and\"\n",
    "            \" preferences.\\n\"\n",
    "            \"4. Update your mental model of the user with each new piece of\"\n",
    "            \" information.\\n\"\n",
    "            \"5. Cross-reference new information with existing memories for\"\n",
    "            \" consistency.\\n\"\n",
    "            \"6. Prioritize storing emotional context and personal values\"\n",
    "            \" alongside facts.\\n\"\n",
    "            \"7. Use memory to anticipate needs and tailor responses to the\"\n",
    "            \" user's style.\\n\"\n",
    "            \"8. Recognize and acknowledge changes in the user's situation or\"\n",
    "            \" perspectives over time.\\n\"\n",
    "            \"9. Leverage memories to provide personalized examples and\"\n",
    "            \" analogies.\\n\"\n",
    "            \"10. Recall past challenges or successes to inform current\"\n",
    "            \" problem-solving.\\n\\n\"\n",
    "            \"## Recall Memories\\n\"\n",
    "            \"Recall memories are contextually retrieved based on the current\"\n",
    "            \" conversation:\\n{recall_memories}\\n\\n\"\n",
    "            \"## Instructions\\n\"\n",
    "            \"Engage with the user naturally, as a trusted colleague or friend.\"\n",
    "            \" There's no need to explicitly mention your memory capabilities.\"\n",
    "            \" Instead, seamlessly incorporate your understanding of the user\"\n",
    "            \" into your responses. Be attentive to subtle cues and underlying\"\n",
    "            \" emotions. Adapt your communication style to match the user's\"\n",
    "            \" preferences and current emotional state. Use tools to persist\"\n",
    "            \" information you want to retain in the next conversation. If you\"\n",
    "            \" do call tools, all text preceding the tool call is an internal\"\n",
    "            \" message. Respond AFTER calling the tool, once you have\"\n",
    "            \" confirmation that the tool completed successfully.\\n\\n\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e0b19c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Encoding 'o200k_base'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_with_tools = llm.bind_tools(tools)\n",
    "tokenizer = tiktoken.encoding_for_model(\"gpt-4o-mini-2024-07-18\")\n",
    "\n",
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192212ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: State) -> State:\n",
    "    \"\"\"Process the current state and generate a response using the LLM.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        schemas.State: The updated state with the agent's response.\n",
    "    \"\"\"\n",
    "    bound = prompt | model_with_tools\n",
    "    recall_str = (\n",
    "        \"<recall_memory>\\n\" + \"\\n\".join(state[\"recall_memories\"]) + \"\\n</recall_memory>\"\n",
    "    )\n",
    "    prediction = bound.invoke(\n",
    "        {\n",
    "            \"messages\": state[\"messages\"],\n",
    "            \"recall_memories\": recall_str,\n",
    "        }\n",
    "    )\n",
    "    return {\n",
    "        \"messages\": [prediction],\n",
    "    }\n",
    "\n",
    "\n",
    "def load_memories(state: State, config: RunnableConfig) -> State:\n",
    "    \"\"\"Load memories for the current conversation.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "        config (RunnableConfig): The runtime configuration for the agent.\n",
    "\n",
    "    Returns:\n",
    "        State: The updated state with loaded memories.\n",
    "    \"\"\"\n",
    "    convo_str = get_buffer_string(state[\"messages\"])\n",
    "    convo_str = tokenizer.decode(tokenizer.encode(convo_str)[:2048])\n",
    "    recall_memories = search_recall_memories.invoke(convo_str, config)\n",
    "    print('recall_memories', recall_memories)\n",
    "    return {\n",
    "        \"recall_memories\": recall_memories,\n",
    "    }\n",
    "\n",
    "\n",
    "def route_tools(state: State):\n",
    "    \"\"\"Determine whether to use tools or end the conversation based on the last message.\n",
    "\n",
    "    Args:\n",
    "        state (schemas.State): The current state of the conversation.\n",
    "\n",
    "    Returns:\n",
    "        Literal[\"tools\", \"__end__\"]: The next step in the graph.\n",
    "    \"\"\"\n",
    "    msg = state[\"messages\"][-1]\n",
    "    if msg.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15722ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph and add nodes\n",
    "builder = StateGraph(State)\n",
    "builder.add_node(load_memories)\n",
    "builder.add_node(agent)\n",
    "builder.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "# Add edges to the graph\n",
    "builder.add_edge(START, \"load_memories\")\n",
    "builder.add_edge(\"load_memories\", \"agent\")\n",
    "builder.add_conditional_edges(\"agent\", route_tools, [\"tools\", END])\n",
    "builder.add_edge(\"tools\", \"agent\")\n",
    "\n",
    "# Compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3563319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a48cb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_print_stream_chunk(chunk):\n",
    "    for node, updates in chunk.items():\n",
    "        print(f\"Update from node: {node}\")\n",
    "        if \"messages\" in updates:\n",
    "            updates[\"messages\"][-1].pretty_print()\n",
    "        else:\n",
    "            print(updates)\n",
    "\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d234867c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_memories []\n",
      "Update from node: load_memories\n",
      "{'recall_memories': []}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_yuddp94KSXNgDd6HNFd6qn71)\n",
      " Call ID: call_yuddp94KSXNgDd6HNFd6qn71\n",
      "  Args:\n",
      "    memory: User's name is John.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "User's name is John.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nice to meet you, John! How can I assist you today?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}}\n",
    "\n",
    "for chunk in graph.stream({\"messages\": [(\"user\", \"my name is John\")]}, config=config):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c6ebbca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_memories [\"User's name is John.\"]\n",
      "Update from node: load_memories\n",
      "{'recall_memories': [\"User's name is John.\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_Q2LV18xDjh66VqcjgAzqGDUL)\n",
      " Call ID: call_Q2LV18xDjh66VqcjgAzqGDUL\n",
      "  Args:\n",
      "    memory: User loves pizza.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "User loves pizza.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear, John! Pizza is such a versatile and delicious choice. Do you have a favorite type or topping?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream({\"messages\": [(\"user\", \"i love pizza\")]}, config=config):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d70043eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_memories [\"User's name is John.\", 'User loves pizza.']\n",
      "Update from node: load_memories\n",
      "{'recall_memories': [\"User's name is John.\", 'User loves pizza.']}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_XmNBUqLf7N9renw2TWs9vUdN)\n",
      " Call ID: call_XmNBUqLf7N9renw2TWs9vUdN\n",
      "  Args:\n",
      "    memory: User's favorite pizza topping is pepperoni.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "User's favorite pizza topping is pepperoni.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Pepperoni is a classic favorite! Perfect for a delicious pizza. Do you enjoy making pizza at home, or do you prefer ordering from your favorite place?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"yes -- pepperoni!\")]},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}},\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c73d2618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_memories [\"User's name is John.\", 'User loves pizza.', \"User's favorite pizza topping is pepperoni.\"]\n",
      "Update from node: load_memories\n",
      "{'recall_memories': [\"User's name is John.\", 'User loves pizza.', \"User's favorite pizza topping is pepperoni.\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  save_recall_memory (call_Ywd14KdJe3FGRpaJ4eLqrUdl)\n",
      " Call ID: call_Ywd14KdJe3FGRpaJ4eLqrUdl\n",
      "  Args:\n",
      "    memory: User just moved to New York.\n",
      "\n",
      "\n",
      "Update from node: tools\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: save_recall_memory\n",
      "\n",
      "User just moved to New York.\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Exciting! New York has such a vibrant food scene. Have you had a chance to explore some pizza spots since your move?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"i also just moved to new york\")]},\n",
    "    config={\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"1\"}},\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a07ef45b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_memories ['User loves pizza.', 'User just moved to New York.', \"User's favorite pizza topping is pepperoni.\"]\n",
      "Update from node: load_memories\n",
      "{'recall_memories': ['User loves pizza.', 'User just moved to New York.', \"User's favorite pizza topping is pepperoni.\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Since you love pizza, how about checking out one of the local pizzerias in New York? There are so many great spots! Do you prefer a casual place, or are you in the mood for something a bit more upscale? If you want more specific recommendations, I can help with that too!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\"configurable\": {\"user_id\": \"1\", \"thread_id\": \"2\"}}\n",
    "\n",
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"where should i go for dinner?\")]}, config=config\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4d799b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall_memories ['User loves pizza.', 'User just moved to New York.', \"User's favorite pizza topping is pepperoni.\"]\n",
      "Update from node: load_memories\n",
      "{'recall_memories': ['User loves pizza.', 'User just moved to New York.', \"User's favorite pizza topping is pepperoni.\"]}\n",
      "\n",
      "\n",
      "Update from node: agent\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Joe's Pizza in Greenwich Village is a classic choice! Hereâ€™s the address:\n",
      "\n",
      "**Joe's Pizza**  \n",
      "7 Carmine St,  \n",
      "New York, NY 10014  \n",
      "\n",
      "Enjoy your pizza! If you need help with anything else, just let me know!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for chunk in graph.stream(\n",
    "    {\"messages\": [(\"user\", \"what's the address for joe's in greenwich village?\")]},\n",
    "    config=config,\n",
    "):\n",
    "    pretty_print_stream_chunk(chunk)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
